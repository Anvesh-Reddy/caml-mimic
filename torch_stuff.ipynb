{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import evaluation\n",
    "import csv\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab_size = 40000\n",
    "embedding_size = 50\n",
    "Y = 10\n",
    "dropout = 0.3\n",
    "kernel_size = 3\n",
    "num_epochs = 5\n",
    "batch_size = 32\n",
    "log_interval = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#yield some tensors. file should hold data sorted by sequence length, for batching\n",
    "def data_generator(filename, batch_size, Y):\n",
    "    with open(filename, 'r') as infile:\n",
    "        r = csv.reader(infile)\n",
    "        #header\n",
    "        next(r)\n",
    "        cur_insts = []\n",
    "        cur_labels = []\n",
    "        cur_length = 0\n",
    "        for row in r:\n",
    "            #find the next batch_size instances with the same length\n",
    "            text = row[1]\n",
    "            length = int(row[3])\n",
    "            if length > cur_length:\n",
    "                if len(cur_insts) > 0:\n",
    "                    #create the tensors\n",
    "                    yield torch.LongTensor(cur_insts), torch.FloatTensor(cur_labels)\n",
    "                    #clear\n",
    "                    cur_insts = []\n",
    "                    cur_labels = []\n",
    "                cur_insts.append([int(w) for w in text.split()])\n",
    "                labels = [int(l) for l in row[2].split(';')]\n",
    "                cur_labels.append([1 if i in labels else 0 for i in range(Y)])\n",
    "                #reset length\n",
    "                cur_length = length\n",
    "            else:\n",
    "                cur_insts.append([int(w) for w in text.split()])\n",
    "                labels = [int(l) for l in row[2].split(';')]\n",
    "                cur_labels.append([1 if i in labels else 0 for i in range(Y)])\n",
    "                if len(cur_insts) == batch_size:\n",
    "                    #create the tensors\n",
    "                    yield torch.LongTensor(cur_insts), torch.FloatTensor(cur_labels)\n",
    "                    #clear\n",
    "                    cur_insts = []\n",
    "                    cur_labels = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, embedding_size)\n",
    "        self.embed_drop = nn.Dropout(p=dropout)\n",
    "        self.conv = nn.Conv1d(embedding_size, Y, kernel_size=kernel_size)\n",
    "        self.conv_drop = nn.Dropout(p=dropout)\n",
    "        self.fc = nn.Linear(Y, Y)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embed_drop(self.embed(x))\n",
    "        x = torch.transpose(x, 1, 2).contiguous()\n",
    "        \n",
    "        x = self.conv_drop(self.conv(x))\n",
    "        \n",
    "        x = F.tanh(F.max_pool1d(x, kernel_size=x.size()[2]))\n",
    "        x = torch.squeeze(x, dim=2)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return F.sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch, dataset):\n",
    "    filename = '../mimicdata/notes_10_train_' + dataset + '_sorted.csv'\n",
    "#     train_loader = data_generator(filename, batch_size, Y)\n",
    "    #just sets the model into 'train' mode\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(data_generator(filename, batch_size, Y)):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        #clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        #forward computation\n",
    "        loss = F.binary_cross_entropy(output, target)\n",
    "        #backward pass\n",
    "        loss.backward()\n",
    "        #kick it in the right direction\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            print('Train Epoch: {} [batch #{}, batch_size {}, seq length {}]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx, data.size()[0], data.size()[1], loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test(epoch, dataset):\n",
    "    filename = '../mimicdata/notes_10_dev_' + dataset + '_sorted.csv'\n",
    "#     test_loader = data_generator(filename, batch_size, Y)\n",
    "    #set model to 'eval' mode\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    y = []\n",
    "    yhat = []\n",
    "    for data, target in data_generator(filename, batch_size, Y):\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        #predict\n",
    "        output = model(data)\n",
    "        test_loss += F.binary_cross_entropy(output, target)\n",
    "        output[output >= 0.5] = 1\n",
    "        output[output < 0.5] = 0\n",
    "        y.append(target.data.numpy())\n",
    "        yhat.append(output.data.numpy())\n",
    "        \n",
    "    y = np.array(y)\n",
    "    yhat = np.array(yhat)\n",
    "    print(y.shape)\n",
    "    print(yhat.shape)\n",
    "    preds, acc, prec, rec, f1 = evaluation.all_metrics(yhat, y)\n",
    "    print(\"acc, prec, rec, f1\")\n",
    "    print(acc, prec, rec, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [batch #0, batch_size 1, seq length 6]\tLoss: 0.191250\n",
      "Train Epoch: 1 [batch #100, batch_size 31, seq length 116]\tLoss: 0.270188\n",
      "Train Epoch: 1 [batch #200, batch_size 7, seq length 160]\tLoss: 0.286168\n",
      "Train Epoch: 1 [batch #300, batch_size 32, seq length 196]\tLoss: 0.261817\n",
      "Train Epoch: 1 [batch #400, batch_size 21, seq length 235]\tLoss: 0.261542\n",
      "Train Epoch: 1 [batch #500, batch_size 32, seq length 278]\tLoss: 0.294199\n",
      "Train Epoch: 1 [batch #600, batch_size 32, seq length 324]\tLoss: 0.292357\n",
      "Train Epoch: 1 [batch #700, batch_size 32, seq length 373]\tLoss: 0.286851\n",
      "Train Epoch: 1 [batch #800, batch_size 14, seq length 466]\tLoss: 0.253943\n",
      "Train Epoch: 1 [batch #900, batch_size 2, seq length 567]\tLoss: 0.234157\n",
      "Train Epoch: 1 [batch #1000, batch_size 4, seq length 671]\tLoss: 0.376286\n",
      "Train Epoch: 1 [batch #1100, batch_size 2, seq length 781]\tLoss: 0.346677\n",
      "Train Epoch: 1 [batch #1200, batch_size 1, seq length 899]\tLoss: 0.229671\n",
      "Train Epoch: 1 [batch #1300, batch_size 1, seq length 1032]\tLoss: 0.197184\n",
      "Train Epoch: 1 [batch #1400, batch_size 1, seq length 1197]\tLoss: 0.214139\n",
      "Train Epoch: 1 [batch #1500, batch_size 1, seq length 1503]\tLoss: 0.176452\n",
      "(1292,)\n",
      "(1292,)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-130-6fd147cd6caa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'single'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'single'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-129-f856fc8a18a7>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(epoch, dataset)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"acc, prec, rec, f1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/james/Windows8_OS/Users/James/Documents/SCHOOL/MS/research/mimic/src/evaluation.py\u001b[0m in \u001b[0;36mall_metrics\u001b[0;34m(yhat, y)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mall_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mall_micro\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/james/Windows8_OS/Users/James/Documents/SCHOOL/MS/research/mimic/src/evaluation.py\u001b[0m in \u001b[0;36maccuracy\u001b[0;34m(yhat, y)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintersect_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0munion_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/james/Windows8_OS/Users/James/Documents/SCHOOL/MS/research/mimic/src/evaluation.py\u001b[0m in \u001b[0;36mintersect_size\u001b[0;34m(yhat, y, axis)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mintersect_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m#axis=0 for label-level union (micro). axis=1 for instance-level (macro)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs):\n",
    "    train(epoch, 'single')\n",
    "    test(epoch, 'single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
